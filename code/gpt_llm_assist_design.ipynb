{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2498ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入DeepSeek API KEY\n",
    "import os\n",
    "\n",
    "os.environ[\"DEEPSEEK_API_KEY\"]='<YOUR_DEEPSEEK_API_KEY>'\n",
    "os.environ[\"LLM_MODEL\"]='deepseek-chat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77bb728",
   "metadata": {},
   "source": [
    "# LLM辅助设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a010569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designing a Twitter-like system involves several key components such as Users, Tweets, Followers, Likes, Retweets, and Notifications. Below is a PlantUML script that represents the business domain model for such a system.\n",
      "\n",
      "```plantuml\n",
      "@startuml\n",
      "' Define the classes\n",
      "class User {\n",
      "    +String userId\n",
      "    +String username\n",
      "    +String email\n",
      "    +String passwordHash\n",
      "    +Date createdAt\n",
      "    +Date updatedAt\n",
      "    +List<Tweet> tweets\n",
      "    +List<User> followers\n",
      "    +List<User> following\n",
      "    +List<Like> likes\n",
      "    +List<Retweet> retweets\n",
      "    +List<Notification> notifications\n",
      "}\n",
      "\n",
      "class Tweet {\n",
      "    +String tweetId\n",
      "    +String content\n",
      "    +Date createdAt\n",
      "    +Date updatedAt\n",
      "    +User author\n",
      "    +List<Like> likes\n",
      "    +List<Retweet> retweets\n",
      "    +List<Reply> replies\n",
      "}\n",
      "\n",
      "class Like {\n",
      "    +String likeId\n",
      "    +User user\n",
      "    +Tweet tweet\n",
      "    +Date createdAt\n",
      "}\n",
      "\n",
      "class Retweet {\n",
      "    +String retweetId\n",
      "    +User user\n",
      "    +Tweet originalTweet\n",
      "    +Date createdAt\n",
      "}\n",
      "\n",
      "class Reply {\n",
      "    +String replyId\n",
      "    +String content\n",
      "    +Date createdAt\n",
      "    +User author\n",
      "    +Tweet parentTweet\n",
      "}\n",
      "\n",
      "class Notification {\n",
      "    +String notificationId\n",
      "    +User recipient\n",
      "    +String message\n",
      "    +Date createdAt\n",
      "    +boolean isRead\n",
      "}\n",
      "\n",
      "' Define the relationships\n",
      "User \"1\" *-- \"0..*\" Tweet : authored by\n",
      "User \"1\" *-- \"0..*\" Like : likes\n",
      "User \"1\" *-- \"0..*\" Retweet : retweets\n",
      "User \"1\" *-- \"0..*\" User : follows\n",
      "User \"1\" *-- \"0..*\" Notification : receives\n",
      "\n",
      "Tweet \"1\" *-- \"0..*\" Like : has\n",
      "Tweet \"1\" *-- \"0..*\" Retweet : has\n",
      "Tweet \"1\" *-- \"0..*\" Reply : has\n",
      "\n",
      "Reply \"1\" *-- \"1\" Tweet : replies to\n",
      "\n",
      "@enduml\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "1. **User**: Represents a user of the system. Each user has a unique `userId`, `username`, `email`, and `passwordHash\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "          Design a twitter like system, represent the business domain model with PlantUML script\n",
    "          \"\"\"}\n",
    "    ],\n",
    "    temperature = 0.2, \n",
    "    max_tokens = 500\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# 生成的PlantUML可以通过网站解析：http://www.plantuml.com/plantuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8c121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designing a Facebook-like system involves multiple components such as User Authentication, Post Creation, News Feed Generation, Notifications, and more. Below is a simplified UML sequence diagram using PlantUML script to represent the interactions between these components.\n",
      "\n",
      "### PlantUML Script\n",
      "\n",
      "```plantuml\n",
      "@startuml\n",
      "actor User\n",
      "participant \"AuthService\" as Auth\n",
      "participant \"PostService\" as Post\n",
      "participant \"NewsFeedService\" as NewsFeed\n",
      "participant \"NotificationService\" as Notification\n",
      "participant \"FriendService\" as Friend\n",
      "\n",
      "User -> Auth: Login(username, password)\n",
      "Auth --> User: AuthToken\n",
      "\n",
      "User -> Post: CreatePost(AuthToken, content)\n",
      "Post --> User: PostID\n",
      "\n",
      "Post -> NewsFeed: AddPostToFeed(PostID, UserID)\n",
      "NewsFeed --> Post: Success\n",
      "\n",
      "Post -> Friend: GetFriends(UserID)\n",
      "Friend --> Post: List<FriendID>\n",
      "\n",
      "Post -> Notification: NotifyFriends(List<FriendID>, PostID)\n",
      "Notification --> Post: Success\n",
      "\n",
      "User -> NewsFeed: GetNewsFeed(AuthToken)\n",
      "NewsFeed -> Post: GetPostsForUser(UserID)\n",
      "Post --> NewsFeed: List<Post>\n",
      "NewsFeed --> User: List<Post>\n",
      "\n",
      "@enduml\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "\n",
      "1. **User Authentication**:\n",
      "   - The `User` interacts with the `AuthService` to log in using their username and password.\n",
      "   - The `AuthService` returns an `AuthToken` upon successful authentication.\n",
      "\n",
      "2. **Post Creation**:\n",
      "   - The `User` sends a request to the `PostService` to create a new post, providing the `AuthToken` and the content of the post.\n",
      "   - The `PostService` creates the post and returns a `PostID`.\n",
      "\n",
      "3. **News Feed Update**:\n",
      "   - The `PostService` sends the `PostID` and `UserID` to the `NewsFeedService` to add the new post to the user's news feed.\n",
      "   - The `NewsFeedService` confirms the addition.\n",
      "\n",
      "4. **Friend Notification**:\n",
      "   - The `PostService` requests the list of friends from the `FriendService` using the `UserID`.\n",
      "   - The `FriendService` returns a list of `FriendID`s.\n",
      "   - The `PostService` then sends a notification to each friend via the `NotificationService`.\n",
      "\n",
      "5. **Fetching News Feed**:\n",
      "   - The\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=os.getenv(\"LLM_MODEL\"),\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "          Design a facebook like system, represent the interactions by UML sequence diagram with PlantUML script\n",
    "          \"\"\"}\n",
    "    ],\n",
    "    temperature = 0.2, \n",
    "    max_tokens = 500\n",
    "  )\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6bc8355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models.base import BaseChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = BaseChatOpenAI(\n",
    "        model=os.getenv(\"LLM_MODEL\"), \n",
    "        openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"), \n",
    "        openai_api_base='https://api.deepseek.com',\n",
    "        max_tokens=1024)\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=10) \n",
    "\n",
    "\n",
    "def get_response(input):\n",
    "    conversation_with_memory = ConversationChain(\n",
    "        llm=llm, \n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "    return conversation_with_memory.predict(input=input)\n",
    "\n",
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=300) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch()\n",
    "\n",
    "#生成一个观察者模式类图，用plantUML script表示\n",
    "#根据上面的UML生成Java代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d969ddb",
   "metadata": {},
   "source": [
    "# LLM生成代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0199eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    # create the token with uuid\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07df4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def work_on(input):\n",
    "    client = OpenAI(api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "                    base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"LLM_MODEL\"),\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a senior software engineer.\"},   \n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        temperature = 0, \n",
    "        max_tokens = 500\n",
    "      )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cbb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_def = \"\"\"\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    # create the token with uuid + input\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d52a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To implement the `TokenCreator` abstract class, we need to create a concrete class that provides an implementation for the `create_token` method. The method should generate a token by combining a UUID with the provided input. Here's how you can implement it:\n",
      "\n",
      "```python\n",
      "import uuid\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "class TokenCreator(ABC):\n",
      "    @abstractmethod\n",
      "    def create_token(self, input: str) -> str:\n",
      "        pass\n",
      "\n",
      "class UUIDTokenCreator(TokenCreator):\n",
      "    def create_token(self, input: str) -> str:\n",
      "        # Generate a UUID\n",
      "        unique_id = uuid.uuid4()\n",
      "        \n",
      "        # Combine the UUID with the input to create the token\n",
      "        token = f\"{unique_id}-{input}\"\n",
      "        \n",
      "        return token\n",
      "\n",
      "# Example usage\n",
      "if __name__ == \"__main__\":\n",
      "    token_creator = UUIDTokenCreator()\n",
      "    token = token_creator.create_token(\"example_input\")\n",
      "    print(f\"Generated Token: {token}\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **UUID Generation**: The `uuid.uuid4()` function generates a random UUID.\n",
      "2. **Token Creation**: The UUID is combined with the input string using an f-string to create the token.\n",
      "3. **Concrete Implementation**: The `UUIDTokenCreator` class implements the `create_token` method, satisfying the requirements of the `TokenCreator` abstract class.\n",
      "\n",
      "### Example Output:\n",
      "If you run the example usage code, you might get an output like:\n",
      "```\n",
      "Generated Token: 123e4567-e89b-12d3-a456-426614174000-example_input\n",
      "```\n",
      "\n",
      "This output will vary each time you run the code because the UUID is randomly generated.\n"
     ]
    }
   ],
   "source": [
    "print(work_on(\"Implement the following abstract class. \\n --- \\n\"+ interface_def))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585c167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927a9a00-1cbf-43c2-9ea1-1f9c5acb3564Hello\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n",
    "class MyTokenCreator(TokenCreator):\n",
    "    def create_token(self, input)->str:\n",
    "        return str(uuid.uuid4()) + input\n",
    "    \n",
    "mtc = MyTokenCreator()\n",
    "print(mtc.create_token(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ca7af",
   "metadata": {},
   "source": [
    "# 生成单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e91dbbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To write a unit test for the `UUIDTokenCreator` class, we can use the `unittest` framework, which is a built-in testing framework in Python. The test will verify that the `create_token` method generates a UUID and appends the input string correctly.\n",
      "\n",
      "Here is the code with the unit test included in the same module:\n",
      "\n",
      "```python\n",
      "import uuid\n",
      "from abc import ABC, abstractmethod\n",
      "import unittest\n",
      "\n",
      "class TokenCreator(ABC):\n",
      "    @abstractmethod\n",
      "    def create_token(self, input) -> str:\n",
      "        pass\n",
      "\n",
      "class UUIDTokenCreator(TokenCreator):\n",
      "    def create_token(self, input) -> str:\n",
      "        return str(uuid.uuid4()) + str(input)\n",
      "\n",
      "class TestUUIDTokenCreator(unittest.TestCase):\n",
      "    def test_create_token(self):\n",
      "        # Arrange\n",
      "        creator = UUIDTokenCreator()\n",
      "        test_input = \"test_input\"\n",
      "\n",
      "        # Act\n",
      "        token = creator.create_token(test_input)\n",
      "\n",
      "        # Assert\n",
      "        # Check that the token starts with a UUID (36 characters long)\n",
      "        self.assertEqual(len(token), 36 + len(test_input))\n",
      "        self.assertTrue(token.startswith(str(uuid.UUID(token[:36]))))\n",
      "        self.assertTrue(token.endswith(test_input))\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main()\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Test Class**: `TestUUIDTokenCreator` is a subclass of `unittest.TestCase`. It contains the test cases for the `UUIDTokenCreator` class.\n",
      "2. **Test Method**: `test_create_token` is a test method that:\n",
      "   - **Arrange**: Creates an instance of `UUIDTokenCreator` and defines a test input string.\n",
      "   - **Act**: Calls the `create_token` method with the test input.\n",
      "   - **Assert**: Checks that the generated token:\n",
      "     - Has the correct length (36 characters for the UUID + the length of the input string).\n",
      "     - Starts with a valid UUID.\n",
      "     - Ends with the input string.\n",
      "3. **Running the Test**: The `unittest.main()` function is called to run the test when the script is executed.\n",
      "\n",
      "### Running the Test:\n",
      "To run the test, simply execute the script. If the test passes, it means the `UUIDTokenCreator` class is working as expected. If it fails, the test will provide information about what went wrong.\n"
     ]
    }
   ],
   "source": [
    "prog = \"\"\"\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n",
    "class UUIDTokenCreator(TokenCreator):\n",
    "    def create_token(self, input)->str:\n",
    "        return str(uuid.uuid4()) + str(input)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(work_on(\"Write the unit test (the unit test in the same module) for the class UUIDTokenCreator in the following code: \\n --- \\n\"+ prog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "358df5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x11455f0e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class TokenCreator(ABC):\n",
    "    @abstractmethod\n",
    "    def create_token(self, input)->str:\n",
    "        pass\n",
    "\n",
    "class UUIDTokenCreator(TokenCreator):\n",
    "    def create_token(self, input)->str:\n",
    "        return str(uuid.uuid4()) + str(input)\n",
    "\n",
    "class TestUUIDTokenCreator(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.token_creator = UUIDTokenCreator()\n",
    "\n",
    "    def test_create_token(self):\n",
    "        input = \"test\"\n",
    "        token = self.token_creator.create_token(input)\n",
    "        self.assertTrue(isinstance(token, str))\n",
    "        self.assertTrue(token.endswith(input))\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    unittest.main()\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647f4d7",
   "metadata": {},
   "source": [
    "# 代码理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a25caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要从网页中提取文字内容，可以使用Python的`requests`库来获取网页内容，然后使用`BeautifulSoup`库来解析HTML并提取文字。以下是一个示例函数：\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def extract_text_from_webpage(url):\n",
      "    try:\n",
      "        # 发送HTTP请求获取网页内容\n",
      "        response = requests.get(url)\n",
      "        response.raise_for_status()  # 检查请求是否成功\n",
      "\n",
      "        # 使用BeautifulSoup解析HTML\n",
      "        soup = BeautifulSoup(response.text, 'html.parser')\n",
      "\n",
      "        # 提取网页中的文字内容\n",
      "        text = soup.get_text(separator='\\n')  # 使用换行符分隔不同元素的文本\n",
      "\n",
      "        return text.strip()  # 去除首尾空白字符\n",
      "\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        return f\"Error fetching the webpage: {e}\"\n",
      "\n",
      "# 示例用法\n",
      "url = \"https://www.example.com\"\n",
      "text_content = extract_text_from_webpage(url)\n",
      "print(text_content)\n",
      "```\n",
      "\n",
      "### 说明：\n",
      "1. **requests.get(url)**: 发送HTTP GET请求以获取网页内容。\n",
      "2. **response.raise_for_status()**: 检查请求是否成功，如果请求失败（如404或500错误），将抛出异常。\n",
      "3. **BeautifulSoup(response.text, 'html.parser')**: 使用BeautifulSoup解析HTML内容。\n",
      "4. **soup.get_text(separator='\\n')**: 提取网页中的所有文本内容，并使用换行符分隔不同元素的文本。\n",
      "5. **text.strip()**: 去除提取的文本内容的首尾空白字符。\n",
      "\n",
      "### 依赖库安装：\n",
      "如果你还没有安装`requests`和`BeautifulSoup`，可以使用以下命令安装：\n",
      "\n",
      "```bash\n",
      "pip install requests beautifulsoup4\n",
      "```\n",
      "\n",
      "### 注意事项：\n",
      "- 该函数提取的是网页中的所有文本内容，包括导航栏、页脚等。如果你只想提取特定部分的文本，可以使用BeautifulSoup的`find`或`find_all`方法来定位特定的HTML元素。\n",
      "- 该函数不处理JavaScript生成的内容。如果需要处理动态加载的内容，可以考虑使用`Selenium`等工具。\n",
      "\n",
      "希望这个函数对你有帮助！\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "编写一个Python函数，输入为一个网页地址，输出该页面上的文字内容。\n",
    "\"\"\"\n",
    "\n",
    "print(work_on(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "316109f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_webpage_text(url):\n",
    "    try:\n",
    "        # 发送HTTP请求\n",
    "        response = requests.get(url)\n",
    "        # 检查请求状态，如果请求成功则继续\n",
    "        if response.status_code == 200:\n",
    "            # 使用BeautifulSoup解析HTML内容\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # 获取所有的文本内容\n",
    "            text = soup.get_text()\n",
    "            return text\n",
    "        else:\n",
    "            return \"Failed to retrieve webpage.\"\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b61a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"An agent designed to hold a conversation in addition to using tools.\"\"\"\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "from typing import Any, List, Optional, Sequence\n",
      "\n",
      "from langchain_core._api import deprecated\n",
      "from langchain_core.callbacks import BaseCallbackManager\n",
      "from langchain_core.language_models import BaseLanguageModel\n",
      "from langchain_core.prompts import PromptTemplate\n",
      "from langchain_core.tools import BaseTool\n",
      "from pydantic import Field\n",
      "\n",
      "from langchain._api.deprecation import AGENT_DEPRECATION_WARNING\n",
      "from langchain.agents.agent import Agent, AgentOutputParser\n",
      "from langchain.agents.agent_types import AgentType\n",
      "from langchain.agents.conversational.output_parser import ConvoOutputParser\n",
      "from langchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX\n",
      "from langchain.agents.utils import validate_tools_single_input\n",
      "from langchain.chains import LLMChain\n",
      "\n",
      "\n",
      "@deprecated(\n",
      "    \"0.1.0\",\n",
      "    message=AGENT_DEPRECATION_WARNING,\n",
      "    removal=\"1.0\",\n",
      ")\n",
      "class ConversationalAgent(Agent):\n",
      "    \"\"\"An agent that holds a conversation in addition to using tools.\"\"\"\n",
      "\n",
      "    ai_prefix: str = \"AI\"\n",
      "    \"\"\"Prefix to use before AI output.\"\"\"\n",
      "    output_parser: AgentOutputParser = Field(default_factory=ConvoOutputParser)\n",
      "    \"\"\"Output parser for the agent.\"\"\"\n",
      "\n",
      "    @classmethod\n",
      "    def _get_default_output_parser(\n",
      "        cls, ai_prefix: str = \"AI\", **kwargs: Any\n",
      "    ) -> AgentOutputParser:\n",
      "        return ConvoOutputParser(ai_prefix=ai_prefix)\n",
      "\n",
      "    @property\n",
      "    def _agent_type(self) -> str:\n",
      "        \"\"\"Return Identifier of agent type.\"\"\"\n",
      "        return AgentType.CONVERSATIONAL_REACT_DESCRIPTION\n",
      "\n",
      "    @property\n",
      "    def observation_prefix(self) -> str:\n",
      "        \"\"\"Prefix to append the observation with.\n",
      "\n",
      "        Returns:\n",
      "            \"Observation: \"\n",
      "        \"\"\"\n",
      "        return \"Observation: \"\n",
      "\n",
      "    @property\n",
      "    def llm_prefix(self) -> str:\n",
      "        \"\"\"Prefix to append the llm call with.\n",
      "\n",
      "        Returns:\n",
      "            \"Thought: \"\n",
      "        \"\"\"\n",
      "        return \"Thought:\"\n",
      "\n",
      "    @classmethod\n",
      "    def create_prompt(\n",
      "        cls,\n",
      "        tools: Sequence[BaseTool],\n",
      "        prefix: str = PREFIX,\n",
      "        suffix: str = SUFFIX,\n",
      "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
      "        ai_prefix: str = \"AI\",\n",
      "        human_prefix: str = \"Human\",\n",
      "        input_variables: Optional[List[str]] = None,\n",
      "    ) -> PromptTemplate:\n",
      "        \"\"\"Create prompt in the style of the zero-shot agent.\n",
      "\n",
      "        Args:\n",
      "            tools: List of tools the agent will have access to, used to format the\n",
      "                prompt.\n",
      "            prefix: String to put before the list of tools. Defaults to PREFIX.\n",
      "            suffix: String to put after the list of tools. Defaults to SUFFIX.\n",
      "            format_instructions: Instructions on how to use the tools. Defaults to\n",
      "                FORMAT_INSTRUCTIONS\n",
      "            ai_prefix: String to use before AI output. Defaults to \"AI\".\n",
      "            human_prefix: String to use before human output.\n",
      "                Defaults to \"Human\".\n",
      "            input_variables: List of input variables the final prompt will expect.\n",
      "                Defaults to [\"input\", \"chat_history\", \"agent_scratchpad\"].\n",
      "\n",
      "        Returns:\n",
      "            A PromptTemplate with the template assembled from the pieces here.\n",
      "        \"\"\"\n",
      "        tool_strings = \"\\n\".join(\n",
      "            [f\"> {tool.name}: {tool.description}\" for tool in tools]\n",
      "        )\n",
      "        tool_names = \", \".join([tool.name for tool in tools])\n",
      "        format_instructions = format_instructions.format(\n",
      "            tool_names=tool_names, ai_prefix=ai_prefix, human_prefix=human_prefix\n",
      "        )\n",
      "        template = \"\\n\\n\".join([prefix, tool_strings, format_instructions, suffix])\n",
      "        if input_variables is None:\n",
      "            input_variables = [\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
      "        return PromptTemplate(template=template, input_variables=input_variables)\n",
      "\n",
      "    @classmethod\n",
      "    def _validate_tools(cls, tools: Sequence[BaseTool]) -> None:\n",
      "        super()._validate_tools(tools)\n",
      "        validate_tools_single_input(cls.__name__, tools)\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm_and_tools(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        tools: Sequence[BaseTool],\n",
      "        callback_manager: Optional[BaseCallbackManager] = None,\n",
      "        output_parser: Optional[AgentOutputParser] = None,\n",
      "        prefix: str = PREFIX,\n",
      "        suffix: str = SUFFIX,\n",
      "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
      "        ai_prefix: str = \"AI\",\n",
      "        human_prefix: str = \"Human\",\n",
      "        input_variables: Optional[List[str]] = None,\n",
      "        **kwargs: Any,\n",
      "    ) -> Agent:\n",
      "        \"\"\"Construct an agent from an LLM and tools.\n",
      "\n",
      "        Args:\n",
      "            llm: The language model to use.\n",
      "            tools: A list of tools to use.\n",
      "            callback_manager: The callback manager to use. Default is None.\n",
      "            output_parser: The output parser to use. Default is None.\n",
      "            prefix: The prefix to use in the prompt. Default is PREFIX.\n",
      "            suffix: The suffix to use in the prompt. Default is SUFFIX.\n",
      "            format_instructions: The format instructions to use.\n",
      "                Default is FORMAT_INSTRUCTIONS.\n",
      "            ai_prefix: The prefix to use before AI output. Default is \"AI\".\n",
      "            human_prefix: The prefix to use before human output.\n",
      "                Default is \"Human\".\n",
      "            input_variables: The input variables to use. Default is None.\n",
      "            **kwargs: Any additional keyword arguments to pass to the agent.\n",
      "\n",
      "        Returns:\n",
      "            An agent.\n",
      "        \"\"\"\n",
      "        cls._validate_tools(tools)\n",
      "        prompt = cls.create_prompt(\n",
      "            tools,\n",
      "            ai_prefix=ai_prefix,\n",
      "            human_prefix=human_prefix,\n",
      "            prefix=prefix,\n",
      "            suffix=suffix,\n",
      "            format_instructions=format_instructions,\n",
      "            input_variables=input_variables,\n",
      "        )\n",
      "        llm_chain = LLMChain(  # type: ignore[misc]\n",
      "            llm=llm,\n",
      "            prompt=prompt,\n",
      "            callback_manager=callback_manager,\n",
      "        )\n",
      "        tool_names = [tool.name for tool in tools]\n",
      "        _output_parser = output_parser or cls._get_default_output_parser(\n",
      "            ai_prefix=ai_prefix\n",
      "        )\n",
      "        return cls(\n",
      "            llm_chain=llm_chain,\n",
      "            allowed_tools=tool_names,\n",
      "            ai_prefix=ai_prefix,\n",
      "            output_parser=_output_parser,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_webpage_text(\"https://raw.githubusercontent.com/langchain-ai/langchain/master/libs/langchain/langchain/agents/conversational/base.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afd0c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个程序定义了一个名为 `ConversationalAgent` 的类，它是一个基于对话的代理（Agent），能够在对话中使用工具（Tools）。以下是对该程序的详细分析：\n",
      "\n",
      "### 1. **导入模块**\n",
      "   - 程序导入了多个模块和类，包括 `deprecated` 装饰器、`BaseCallbackManager`、`BaseLanguageModel`、`PromptTemplate`、`BaseTool` 等。这些模块和类主要用于构建和管理对话代理。\n",
      "   - `deprecated` 装饰器用于标记某个类或方法即将被弃用，并提供了弃用的版本号和警告信息。\n",
      "\n",
      "### 2. **`ConversationalAgent` 类**\n",
      "   - `ConversationalAgent` 继承自 `Agent` 类，表示它是一个代理（Agent），并且专门用于处理对话。\n",
      "   - 该类的主要功能是管理对话流程，并在对话中使用工具（Tools）来执行特定的任务。\n",
      "\n",
      "#### 2.1 **类属性**\n",
      "   - `ai_prefix`: 用于在 AI 输出前添加前缀，默认值为 `\"AI\"`。\n",
      "   - `output_parser`: 用于解析代理的输出，默认使用 `ConvoOutputParser`。\n",
      "\n",
      "#### 2.2 **类方法**\n",
      "   - `_get_default_output_parser`: 返回默认的输出解析器 `ConvoOutputParser`。\n",
      "   - `_agent_type`: 返回代理的类型标识符，这里是 `AgentType.CONVERSATIONAL_REACT_DESCRIPTION`。\n",
      "   - `observation_prefix`: 返回观察结果的前缀，默认是 `\"Observation: \"`。\n",
      "   - `llm_prefix`: 返回 LLM（语言模型）调用的前缀，默认是 `\"Thought:\"`。\n",
      "\n",
      "#### 2.3 **`create_prompt` 方法**\n",
      "   - 该方法用于创建对话代理的提示模板（Prompt Template）。\n",
      "   - 它接受多个参数，包括工具列表、前缀、后缀、格式指令、AI 前缀、人类前缀等。\n",
      "   - 方法内部将工具的描述和名称格式化为字符串，并将这些字符串与格式指令、前缀、后缀等组合成一个完整的提示模板。\n",
      "   - 最终返回一个 `PromptTemplate` 对象。\n",
      "\n",
      "#### 2.4 **`_validate_tools` 方法**\n",
      "   - 该方法用于验证工具列表，确保工具列表中的工具是有效的。\n",
      "   - 它调用了父类的 `_validate\n"
     ]
    }
   ],
   "source": [
    "code = get_webpage_text(\"https://raw.githubusercontent.com/langchain-ai/langchain/master/libs/langchain/langchain/agents/conversational/base.py\")\n",
    "print(work_on(\"分析下面的程序：\\n ---- \\n\"+ code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de5b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
