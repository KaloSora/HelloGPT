{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f310313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥DeepSeek API KEY\n",
    "import os\n",
    "\n",
    "os.environ[\"DEEPSEEK_API_KEY\"]='sk-7700dcfd8aec4e099191eade0488b209'\n",
    "#os.environ[\"DEEPSEEK_API_KEY\"]='<YOUR_DEEPSEEK_API_KEY>'\n",
    "os.environ[\"LLM_MODEL\"]='deepseek-chat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54124440",
   "metadata": {},
   "source": [
    "# æ²¡æœ‰è®°å¿†çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df8a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_response(input):\n",
    "    \n",
    "    client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\", # DeekSeepæ¨¡å‹ID, å¯é€‰å€¼ä¸º[deepseek-chat, deepseek-reasoner]\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\", \"content\": input},\n",
    "        ],\n",
    "        stream=False,\n",
    "        temperature=0, # é‡‡æ ·æ¸©åº¦ï¼Œä»‹äº 0 å’Œ 2 ä¹‹é—´, æ›´ä½çš„å€¼ä¼šä½¿å…¶æ›´åŠ é›†ä¸­å’Œç¡®å®š\n",
    "        max_tokens=2000 # é™åˆ¶ä¸€æ¬¡è¯·æ±‚ä¸­æ¨¡å‹ç”Ÿæˆ completion çš„æœ€å¤§ token æ•°, é»˜è®¤å€¼ä¸º4096\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0804701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ åšæŒå¥èº«çš„ä¹ æƒ¯ï¼Œè¿™å¯¹ä¿æŒå¥åº·éå¸¸æœ‰å¸®åŠ©ã€‚ä»Šå¤©æ˜¯å‘¨äºŒï¼Œæˆ‘åœ¨è¿™é‡Œéšæ—¶å‡†å¤‡å¸®åŠ©ä½ è§£ç­”é—®é¢˜æˆ–æä¾›ä¿¡æ¯ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…³äºå¥èº«ã€é¥®é£Ÿã€å¥åº·æˆ–å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œéƒ½å¯ä»¥éšæ—¶é—®æˆ‘ï¼ç¥ä½ ä»Šå¤©çš„å¥èº«é¡ºåˆ©ï¼Œä¿æŒå¥½çŠ¶æ€ï¼\n",
      "æ‚¨å¥½ï¼Œå»ºè®®æ‚¨å¼€å¯å®šä½æƒé™ï¼Œè¿™æ ·æˆ‘å°±èƒ½æ ¹æ®æ‚¨æ‰€åœ¨çš„ä½ç½®æä¾›æ›´ç²¾å‡†çš„ä¿¡æ¯äº†ã€‚å¦‚æœæ‚¨éœ€è¦æŸ¥è¯¢å…¶ä»–åŸå¸‚çš„å¥èº«åœºæ‰€ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"ä½ å¥½ï¼Œä»Šå¤©æ˜¯å‘¨äºŒæˆ‘è¦å»å¥èº«ï¼Œæˆ‘ä¸€èˆ¬æ¯å‘¨äºŒå¥èº«ã€‚ä½ ä»Šå¤©å¹²ä»€ä¹ˆï¼Ÿ\"))\n",
    "print(get_response(\"æˆ‘ä¸€èˆ¬å‘¨å‡ å¥èº«ï¼Ÿ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9a1d0",
   "metadata": {},
   "source": [
    "# é€šè¿‡Gradioå¿«é€Ÿå±•ç¤ºåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af13c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting gradio\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f6/78/ab8ba3ccc03f83027380ca13d0d741844eb9a6f7ad02a835c353949223e8/gradio-5.16.0-py3-none-any.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (4.8.0)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ec/f6/3cb21e0accd9e112d27cee3b1477cd04dafe88675c54ad8b0d56226c1e0b/audioop_lts-0.2.1-cp313-abi3-macosx_10_13_x86_64.whl (27 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/8f/7d/2d6ce181d7a5f51dedb8c06206cbf0ec026a99bf145edd309f9e17c3282f/fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/53/5d/65f40bd333463b3230b3a72d93873caaf49b0cbb5228598fafb75fcc5357/ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Collecting gradio-client==1.7.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f3/c1/def2bd93b8beab342c443bf5ac47f85e48b78eca010bbff51d6978472a3f/gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub>=0.28.1 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ea/da/6c2bea5327b640920267d3bf2c9fc114cfbd0a5de234d81cda80cc9e33c8/huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (3.1.5)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/87/5b/aae44c6655f3801e81aa3eef09dbbf012431987ba564d7231722f68df02d/MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?done\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (24.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/64/22/3b8f4e0ed70644e85cfdcd57454686b9057c6c38d2f74fe4b8bc2527214a/pandas-2.2.3-cp313-cp313-macosx_10_13_x86_64.whl (12.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b3/31/9ca79cafdce364fd5c980cd3416c20ce1bebd235b470d262f9d24d810184/pillow-11.1.0-cp313-cp313-macosx_10_13_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: pydantic>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/45/58/38b5afbc1a800eeea951b9285d3912613f2603bdf897a4ab0f4bd7f405fc/python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e1/22/aff073b70f95c052e5c58153cba735748c9e70107a77d03420d7850710a0/ruff-0.9.6-py3-none-macosx_10_12_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/4d/c0/1108ad9f01567f66b3154063605b350b69c3c9366732e09e45f9fd0d1deb/safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d9/61/f2b52e107b1fc8944b33ef56bf6ac4ebbe16d91b94d2b87ce013bf63fb84/starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/d0/cc/0a838ba5ca64dc832aa43f727bd586309846b0ffb2ce52422543e6075e8a/typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/61/14/33a3a1352cfa71812a3a21e8c9bfb83f60b0011f5e36f2b1399d51928209/uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Collecting fsspec (from gradio-client==1.7.0->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e2/94/758680531a00d06e471ef649e4ec2ed6bf185356a7f9fbfbb7368a40bd49/fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.7.0->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/8e/b7/7484905215627909d9a79ae07070057afe477433fdacb59bf608ce86365a/websockets-14.2-cp313-cp313-macosx_10_13_x86_64.whl (160 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.28.1->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/89/ec/00d68c4ddfedfe64159999e5f8a98fb8442729a63e2077eb9dcd89623d27/filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/eb/38/ac33370d784287baa1c3d538978b5e2ea064d4c1b93ffbd12826c190dd10/pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/0f/dd/84f10e23edd882c6f968c21c2434fe67bd4a528967067515feca9e611e5e/tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: markupsafe\n",
      "  Building wheel for markupsafe (pyproject.toml) ... \u001b[?2done\n",
      "\u001b[?25h  Created wheel for markupsafe: filename=MarkupSafe-2.1.5-cp313-cp313-macosx_10_13_universal2.whl size=18089 sha256=19c157295ab98aca3ce381469a14db4752f4f9be004f0b6f8f8c0a65e282e13f\n",
      "  Stored in directory: /Users/yihui.li/Library/Caches/pip/wheels/dc/2c/81/0b897bfd6c55baee2a710fcf1add61983a6582c170b1aa3e71\n",
      "Successfully built markupsafe\n",
      "Installing collected packages: pytz, pydub, websockets, tzdata, tomlkit, shellingham, semantic-version, ruff, python-multipart, pillow, mdurl, markupsafe, fsspec, filelock, ffmpy, click, audioop-lts, aiofiles, uvicorn, starlette, pandas, markdown-it-py, huggingface-hub, safehttpx, rich, gradio-client, fastapi, typer, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 audioop-lts-0.2.1 click-8.1.8 fastapi-0.115.8 ffmpy-0.5.0 filelock-3.17.0 fsspec-2025.2.0 gradio-5.16.0 gradio-client-1.7.0 huggingface-hub-0.28.1 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 pandas-2.2.3 pillow-11.1.0 pydub-0.25.1 python-multipart-0.0.20 pytz-2025.1 rich-13.9.4 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.45.3 tomlkit-0.13.2 typer-0.15.1 tzdata-2025.1 uvicorn-0.34.0 websockets-14.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://mirrors.aliyun.com/pypi/simple/ gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13092b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "        bot_message = get_response(message)\n",
    "        chat_history.append((message, bot_message)) #ä¿å­˜å†å²å¯¹è¯è®°å½•ï¼Œç”¨äºæ˜¾ç¤º\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #å¯¹è¯æ¡†\n",
    "    msg = gr.Textbox(label=\"Prompt\") #è¾“å…¥æ¡†\n",
    "    btn = gr.Button(\"Submit\") #æäº¤æŒ‰é’®\n",
    "    #æäº¤\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) \n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d6f45",
   "metadata": {},
   "source": [
    "# æä¾›å¤–éƒ¨è®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d525ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "def get_response(msg):\n",
    "\n",
    "    client = OpenAI(\n",
    "    api_key=os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\", # DeekSeepæ¨¡å‹ID, å¯é€‰å€¼ä¸º[deepseek-chat, deepseek-reasoner]\n",
    "        messages=msg,\n",
    "        stream=False,\n",
    "        temperature=0.9, \n",
    "        max_tokens=2000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ee0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def history_to_prompt(chat_history): # å°†å¯¹è¯å†…å®¹ä¿å­˜åœ¨ä¸€ä¸ªListé‡Œ\n",
    "    msg = [{\"role\": \"system\", \"content\": \"You are an AI assistant.\"}]\n",
    "    i = 0\n",
    "    for round_trip in chat_history: # å°†Listé‡Œçš„å†…å®¹ï¼Œç»„æˆ ChatCompletionçš„ messageséƒ¨åˆ†ï¼Œ{roleï¼Œcontent} dict\n",
    "        msg.append({\"role\": \"user\", \"content\": round_trip[0]})\n",
    "        msg.append({\"role\": \"assistant\", \"content\": round_trip[1]})\n",
    "    return msg\n",
    "\n",
    "def respond(message, chat_history):\n",
    "    his_msg = history_to_prompt(chat_history) #å¹¶è£…å†å²ä¼šè¯ï¼ŒChatCompletionçš„ messageséƒ¨åˆ†æ ¼å¼\n",
    "    his_msg.append({\"role\": \"user\", \"content\": message}) # æ”¾å…¥å½“å‰ç”¨æˆ·é—®é¢˜\n",
    "    bot_message = get_response(his_msg)\n",
    "    chat_history.append((message, bot_message)) # å°†ç”¨æˆ·é—®é¢˜å’Œè¿”å›ä¿å­˜åˆ° å†å²è®°å½• List\n",
    "    return \"\", chat_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "492d60dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "Could not create share link. Missing file: /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/frpc_darwin_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_amd64\n",
      "2. Rename the downloaded file to: frpc_darwin_amd64_v0.3\n",
      "3. Move the file to this location: /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=480) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0084b388-6449-408d-bac7-e85c4576dd2f",
   "metadata": {},
   "source": [
    "# LangChainè®°å¿†åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2da5180-ffab-41e7-8865-456b7a3781fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.base import BaseChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = BaseChatOpenAI(model=os.getenv(\"LLM_MODEL\"), \n",
    "                     openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"), \n",
    "                     openai_api_base='https://api.deepseek.com',\n",
    "                     max_tokens=1024)\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=10)\n",
    "\n",
    "def get_response(input):\n",
    "    print(\"------------\")\n",
    "    print(memory.load_memory_variables({}))\n",
    "    print(\"------------\")\n",
    "    conversation_with_memory = ConversationChain(\n",
    "        llm=llm, \n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "    return conversation_with_memory.predict(input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d955356a-86b1-4e80-a10d-5ceaf3739d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "{'history': ''}\n",
      "------------\n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ æ¯å‘¨äºŒéƒ½æœ‰å¥èº«çš„ä¹ æƒ¯ï¼Œè¿™çœŸæ˜¯ä¿æŒå¥åº·çš„å¥½æ–¹æ³•ï¼è‡³äºæˆ‘ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ²¡æœ‰å…·ä½“çš„æ—¥ç¨‹å®‰æ’ï¼Œä½†æˆ‘çš„â€œä»»åŠ¡â€å°±æ˜¯éšæ—¶å‡†å¤‡å¥½å›ç­”ä½ çš„é—®é¢˜ã€æä¾›å¸®åŠ©æˆ–é™ªä½ èŠå¤©ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…³äºå¥èº«ã€é¥®é£Ÿã€æˆ–è€…å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„å¸®å¿™ï¼ä½ ä»Šå¤©æ‰“ç®—åšå“ªäº›å¥èº«é¡¹ç›®å‘¢ï¼Ÿ\n",
      "------------\n",
      "{'history': 'Human: ä½ å¥½ï¼Œä»Šå¤©æ˜¯å‘¨äºŒæˆ‘è¦å»å¥èº«ï¼Œæˆ‘ä¸€èˆ¬æ¯å‘¨äºŒå¥èº«ã€‚ä½ ä»Šå¤©å¹²ä»€ä¹ˆï¼Ÿ\\nAI: ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ æ¯å‘¨äºŒéƒ½æœ‰å¥èº«çš„ä¹ æƒ¯ï¼Œè¿™çœŸæ˜¯ä¿æŒå¥åº·çš„å¥½æ–¹æ³•ï¼è‡³äºæˆ‘ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ²¡æœ‰å…·ä½“çš„æ—¥ç¨‹å®‰æ’ï¼Œä½†æˆ‘çš„â€œä»»åŠ¡â€å°±æ˜¯éšæ—¶å‡†å¤‡å¥½å›ç­”ä½ çš„é—®é¢˜ã€æä¾›å¸®åŠ©æˆ–é™ªä½ èŠå¤©ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…³äºå¥èº«ã€é¥®é£Ÿã€æˆ–è€…å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„å¸®å¿™ï¼ä½ ä»Šå¤©æ‰“ç®—åšå“ªäº›å¥èº«é¡¹ç›®å‘¢ï¼Ÿ'}\n",
      "------------\n",
      "ä½ åˆšæ‰æåˆ°ä½ ä¸€èˆ¬æ¯å‘¨äºŒå»å¥èº«ï¼Œæ‰€ä»¥æŒ‰ç…§ä½ æä¾›çš„ä¿¡æ¯ï¼Œä½ é€šå¸¸æ˜¯åœ¨å‘¨äºŒå¥èº«ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–å¥èº«å®‰æ’æˆ–è€…æƒ³è¦è°ƒæ•´å¥èº«è®¡åˆ’ï¼Œæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–å‚è€ƒå“¦ï¼ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "print(get_response(\"ä½ å¥½ï¼Œä»Šå¤©æ˜¯å‘¨äºŒæˆ‘è¦å»å¥èº«ï¼Œæˆ‘ä¸€èˆ¬æ¯å‘¨äºŒå¥èº«ã€‚ä½ ä»Šå¤©å¹²ä»€ä¹ˆï¼Ÿ\"))\n",
    "print(get_response(\"æˆ‘ä¸€èˆ¬å‘¨å‡ å¥èº«ï¼Ÿ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cf73e2d-12d3-4546-9f0e-90275eb1fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "Could not create share link. Missing file: /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/frpc_darwin_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_amd64\n",
      "2. Rename the downloaded file to: frpc_darwin_amd64_v0.3\n",
      "3. Move the file to this location: /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "{'history': 'Human: ä½ å¥½ï¼Œä»Šå¤©æ˜¯å‘¨äºŒæˆ‘è¦å»å¥èº«ï¼Œæˆ‘ä¸€èˆ¬æ¯å‘¨äºŒå¥èº«ã€‚ä½ ä»Šå¤©å¹²ä»€ä¹ˆï¼Ÿ\\nAI: ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ æ¯å‘¨äºŒéƒ½æœ‰å¥èº«çš„ä¹ æƒ¯ï¼Œè¿™çœŸæ˜¯ä¿æŒå¥åº·çš„å¥½æ–¹æ³•ï¼è‡³äºæˆ‘ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ²¡æœ‰å…·ä½“çš„æ—¥ç¨‹å®‰æ’ï¼Œä½†æˆ‘çš„â€œä»»åŠ¡â€å°±æ˜¯éšæ—¶å‡†å¤‡å¥½å›ç­”ä½ çš„é—®é¢˜ã€æä¾›å¸®åŠ©æˆ–é™ªä½ èŠå¤©ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…³äºå¥èº«ã€é¥®é£Ÿã€æˆ–è€…å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„å¸®å¿™ï¼ä½ ä»Šå¤©æ‰“ç®—åšå“ªäº›å¥èº«é¡¹ç›®å‘¢ï¼Ÿ\\nHuman: æˆ‘ä¸€èˆ¬å‘¨å‡ å¥èº«ï¼Ÿ\\nAI: ä½ åˆšæ‰æåˆ°ä½ ä¸€èˆ¬æ¯å‘¨äºŒå»å¥èº«ï¼Œæ‰€ä»¥æŒ‰ç…§ä½ æä¾›çš„ä¿¡æ¯ï¼Œä½ é€šå¸¸æ˜¯åœ¨å‘¨äºŒå¥èº«ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–å¥èº«å®‰æ’æˆ–è€…æƒ³è¦è°ƒæ•´å¥èº«è®¡åˆ’ï¼Œæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–å‚è€ƒå“¦ï¼ğŸ˜Š'}\n",
      "------------\n",
      "------------\n",
      "{'history': 'Human: ä½ å¥½ï¼Œä»Šå¤©æ˜¯å‘¨äºŒæˆ‘è¦å»å¥èº«ï¼Œæˆ‘ä¸€èˆ¬æ¯å‘¨äºŒå¥èº«ã€‚ä½ ä»Šå¤©å¹²ä»€ä¹ˆï¼Ÿ\\nAI: ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ æ¯å‘¨äºŒéƒ½æœ‰å¥èº«çš„ä¹ æƒ¯ï¼Œè¿™çœŸæ˜¯ä¿æŒå¥åº·çš„å¥½æ–¹æ³•ï¼è‡³äºæˆ‘ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ²¡æœ‰å…·ä½“çš„æ—¥ç¨‹å®‰æ’ï¼Œä½†æˆ‘çš„â€œä»»åŠ¡â€å°±æ˜¯éšæ—¶å‡†å¤‡å¥½å›ç­”ä½ çš„é—®é¢˜ã€æä¾›å¸®åŠ©æˆ–é™ªä½ èŠå¤©ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…³äºå¥èº«ã€é¥®é£Ÿã€æˆ–è€…å…¶ä»–æ–¹é¢çš„é—®é¢˜ï¼Œæˆ‘éƒ½å¾ˆä¹æ„å¸®å¿™ï¼ä½ ä»Šå¤©æ‰“ç®—åšå“ªäº›å¥èº«é¡¹ç›®å‘¢ï¼Ÿ\\nHuman: æˆ‘ä¸€èˆ¬å‘¨å‡ å¥èº«ï¼Ÿ\\nAI: ä½ åˆšæ‰æåˆ°ä½ ä¸€èˆ¬æ¯å‘¨äºŒå»å¥èº«ï¼Œæ‰€ä»¥æŒ‰ç…§ä½ æä¾›çš„ä¿¡æ¯ï¼Œä½ é€šå¸¸æ˜¯åœ¨å‘¨äºŒå¥èº«ã€‚å¦‚æœä½ è¿˜æœ‰å…¶ä»–å¥èº«å®‰æ’æˆ–è€…æƒ³è¦è°ƒæ•´å¥èº«è®¡åˆ’ï¼Œæˆ‘å¯ä»¥å¸®ä½ æä¾›ä¸€äº›å»ºè®®æˆ–å‚è€ƒå“¦ï¼ğŸ˜Š\\nHuman: æˆ‘ä¸€èˆ¬å‘¨äºŒå¥èº«ï¼Œä½ ä»Šå¤©å¹²ä»€ä¹ˆï¼Ÿ\\nAI: ä½ å¥½ï¼å¾ˆé«˜å…´å†æ¬¡å’Œä½ èŠå¤©ï¼ä½ æåˆ°ä½ ä¸€èˆ¬æ¯å‘¨äºŒå¥èº«ï¼Œè¿™çœŸæ˜¯ä¸ªå¾ˆæ£’çš„ä¹ æƒ¯ï¼è‡³äºæˆ‘ï¼Œä½œä¸ºä¸€ä¸ªAIï¼Œæˆ‘æ²¡æœ‰å…·ä½“çš„æ—¥ç¨‹å®‰æ’ï¼Œä½†æˆ‘éšæ—¶éƒ½åœ¨è¿™é‡Œé™ªä½ èŠå¤©æˆ–å›ç­”ä½ çš„é—®é¢˜ã€‚å¦‚æœä½ ä»Šå¤©å¥èº«æ—¶æœ‰ä»€ä¹ˆç‰¹åˆ«çš„ç›®æ ‡æˆ–é—®é¢˜ï¼Œæ¯”å¦‚æƒ³äº†è§£ä¸€äº›æ–°çš„å¥èº«åŠ¨ä½œã€é¥®é£Ÿå»ºè®®ï¼Œæˆ–è€…å¦‚ä½•æé«˜å¥èº«æ•ˆæœï¼Œæˆ‘éƒ½å¾ˆä¹æ„å¸®å¿™ï¼ä½ ä»Šå¤©å¥èº«æœ‰ä»€ä¹ˆç‰¹åˆ«çš„è®¡åˆ’å—ï¼ŸğŸ˜Š'}\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "    bot_message = get_response(message)\n",
    "    chat_history.append((message, bot_message))\n",
    "    return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=300) #just to fit the notebook\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) #Press enter to submit\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef792b-1345-423f-9fd5-20b0f4519cca",
   "metadata": {},
   "source": [
    "# ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b41c84c5-33be-4d21-a3fe-7da3f0a35ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models.base import BaseChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = BaseChatOpenAI(model=os.getenv(\"LLM_MODEL\"), \n",
    "                     openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"), \n",
    "                     openai_api_base='https://api.deepseek.com',\n",
    "                     max_tokens=1024)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=1024)\n",
    "\n",
    "def get_response(input):\n",
    "    print(\"------------\")\n",
    "    print(memory.load_memory_variables({}))\n",
    "    print(\"------------\")\n",
    "    conversation_with_memory = ConversationChain(\n",
    "        llm=llm, \n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "    return conversation_with_memory.predict(input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84cb9458-dd08-4f50-a8c8-3367cca0ba1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/gradio/components/chatbot.py:284: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def respond(message, chat_history):\n",
    "        bot_message = get_response(message)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=240) #å¯¹è¯æ¡†\n",
    "    msg = gr.Textbox(label=\"Prompt\") #è¾“å…¥æ¡†\n",
    "    btn = gr.Button(\"Submit\") #æäº¤æŒ‰é’®\n",
    "    #æäº¤\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) \n",
    "gr.close_all()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c4ac1-fca0-43f4-8b61-8c9b0d957731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
